"""
This module implements the sequential data preprocessing method proposed by Wang et al. (2025).

Classes: 
-Preprocessor: A base class for preprocessors.
-SequentialPreprocessor: An implementation of the sequential data preprocessing method proposed 
by Wang et al. (2025).

Usage: 
from CFRL import preprocessor
"""

from abc import abstractmethod
import numpy as np
from sklearn.linear_model import LinearRegression
from .utils.base_models import NeuralNetRegressor
#from utils.utils import timer_func
from sklearn.model_selection import KFold
from sklearn.preprocessing import OneHotEncoder
from typing import Union, Literal


class Preprocessor:
    """
    Base class for preprocessors.

    Subclasses must implement the `preprocess_single_step` and `preprocess_multiple_steps` 
    methods.
    """

    def __init__(self) -> None:
        pass
    
    @abstractmethod
    def preprocess_single_step(
            self, 
            z: list | np.ndarray, 
            xt: list | np.ndarray, 
            xtm1: list | np.ndarray | None = None, 
            atm1: list | np.ndarray | None = None, 
            rtm1: list | np.ndarray | None = None, 
            **kwargs
        ) -> tuple[np.ndarray, np.ndarray] | np.ndarray:
        """
        An abstract prototype of methods that preprocess the states at a single time step.
        """
        
        pass

    @abstractmethod
    def preprocess_multiple_steps(
            self, 
            zs: list | np.ndarray, 
            xs: list | np.ndarray, 
            actions: list | np.ndarray, 
            rewards: list | np.ndarray | None = None, 
            **kwargs
        ) -> tuple[np.ndarray, np.ndarray] | np.ndarray:
        """
        An abstract prototype of methods that preprocess a whole trajectory.
        """

        pass

    @staticmethod
    def standardize(
            x: np.ndarray, 
            mean: np.ndarray | None = None, 
            std: np.ndarray | None = None
        ) -> tuple[np.ndarray, np.ndarray, np.ndarray] | np.ndarray:
        if mean is None and std is None:
            mean = np.mean(x, axis=0)
            std = np.std(x, axis=0)
            return (x - mean) / std, mean, std
        else:
            return (x - mean) / std

    @staticmethod
    def destandardize(
            x: np.ndarray, 
            mean: np.ndarray, 
            std: np.ndarray
        ) -> np.ndarray:
        return x * std + mean

    def reset_buffer(self, n: int) -> None:
        self.buffer = {}
        for key, prob in self.marginal_dist_z.items():
            self.buffer[key] = np.zeros((n, self.xdim))

    '''def _hash_tuples(self, tuples):
        if tuples.ndim == 1:
            hashing_tuples = "_".join(np.array(tuples).astype("str"))
        else:
            hashing_tuples = np.apply_along_axis(
                lambda x: "_".join(np.array(x).astype("str")), axis=1, arr=tuples
            )
        return hashing_tuples

    def _reverse_hash_tuples(self, hashing_tuples):
        if isinstance(hashing_tuples, str):
            tuples = np.array(hashing_tuples.split("_")).astype("float")
        else:
            tuples = np.apply_along_axis(
                lambda x: np.array(x.split("_")).astype("float"),
                axis=0,
                arr=hashing_tuples,
            )
        return tuples'''


class SequentialPreprocessor(Preprocessor):
    r"""
    Implementation of the sequential data preprocessing method proposed by Wang et al. (2025).

    The preprocessor first learns a model :math:`\mu(s, a, z)` of the transition dynamics of 
    the MDP underlying the input trajectory. Then, at each time step, it uses :math:`\mu` to 
    reconstruct the counterfactual states and concatenates the reconstructed counterfactual 
    states into a new augmented state vector.

    That is, let :math:`z_i` be the observed sensitive attribute. At t=0 (i.e. the initial 
    time step), for each individual :math:`i` and sensitive attribute level :math:`z`, the 
    preprocessor calculates 

    ..math::
        \hat{s}_{i1}^z = s_{i1} - \hat{\mathbf{E}}(S_1|Z=z_i) + \hat{\mathbf{E}}(S_1|Z=z)

    and forms :math:`\tilde{s}_{i1} = [\hat{s}_{i1}^{z^{(1)}}, \dots, \hat{s}_{i1}^{z^{(K)}}]`.

    At t>0, for each individual :math:`i` and sensitive attribute level :math:`z`, the 
    preprocessor calculates

    ..math::
        [\hat{s}_{it}^z, \hat{r}_{i,t-1}^z] = s_{i1} - \hat{\mu}(s_{i,t-1}, a_{i,t-1}, z_i) 
            + \hat{\mu}(\hat{s}_{i,t-1}^z, a_{i,t-1}, z)

    and forms :math:`\tilde{s}_{it} = [\hat{s}_{it}^{z^{(1)}}, \dots, \hat{s}_{it}^{z^{(K)}}]` 
    and :math:`\tilde{r}_{i,t-1} = \Sigma_{k=1}^K\hat{\mathbb{P}}(Z=z^{(k)})\hat{r}_{i,t-1}^{z^{(K)}}`.

    Refrences: 
        .. [1] Wang, J., Shi, C., Piette, J.D., Loftus, J.R., Zeng, D. and Wu, Z., 2025. 
               Counterfactually Fair Reinforcement Learning via Sequential Data 
               Preprocessing. arXiv preprint arXiv:2501.06366.
    """

    def __init__(
        self,
        z_space: list | np.ndarray,
        #action_space: list | np.ndarray | None = None,
        num_actions: int, 
        cross_folds: int = 1,
        mode: Literal["single", "sensitive"] = "single", 
        reg_model: Literal["lm", "nn"] = "nn",
        hidden_dims: list[int] = [64, 64], 
        epochs: int = 1000,
        learning_rate: int | float = 0.005,
        batch_size: int = 512,
        is_action_onehot: bool = True,
        is_normalized: bool = False,
        is_early_stopping: bool = False,
        test_size: int | float = 0.2,
        early_stopping_patience: int = 10,
        early_stopping_min_delta: int | float = 0.01,
    ) -> None:
        """
        Args: 
            z_space (list or np.ndarray): A 2D list or array of shape (K, zdim) where K is the 
                total number of legit values of the sensitive attribute and zdim is the dimension  
                of the sensitive attribute variable. It contains all legit values of the sensitive 
                attribute. Each legit value should occupy a separate row.
            num_actions (int): The total number of legit actions. 
            cross_folds (int, optional): The number of cross folds used during training. When 
                `cross_folds=k`, the preprocessor will learn `k` models using different subset of 
                the training data, and the final output of `preprocess_single_step` and 
                `preprocess_multiple_steps` will be generally the average of the outputs from each 
                of the `k` models.
            mode (str, optional): Can either be "single" or "sensitive". When `mode="single"`, 
                the preprocessor will learn a single model of the transition dynamics where the 
                sensitive attribute is an input to the model. When `mode="sensitive"`, the preprocessor 
                will learn one transition dynamics model for each level of the sensitive 
                attribute, and transitions under each sensitive attribute :math:`z` will 
                be estimated using the model corresponding to :math:`z`.
            reg_model (str, optional): The type of the model used for learning the transition  
                dynamics. Can be "lm" (polynomial regression) or "nn" (neural network).
            hidden_dims (list[int], optional): The hidden dimensions of the neural network. This 
                argument is not used if `reg_model="lm"`.
            epochs (int, optional): The number of training epochs for the neural network. This 
                argument is not used if `reg_model="lm"`. 
            learning_rate (int or float, optional): The learning rate of the neural netowrk. This 
                argument is not used if `reg_model="lm"`. 
            batch_size (int, optional): The batch size of the neural network. This argument is 
                not used if `reg_model="lm"`.
            is_action_onehot (bool, optional): When set to `True`, the actions will be one-hot 
                encoded. 
            is_normalized (bool, optional): When set to `True`, the states will be normalized 
                following the formula `x_normalized = (x - mean(x)) / std(x)`.
            is_early_stopping (bool, optional): When set to `True`, will enforce early stopping 
                during neural network training. This argument is not used if `reg_model="lm"`.
            test_size (int or float, optional): An int or float between 0 and 1 (inclusive) that 
                specifies size of the test set used for early stopping. This argument is not used 
                if `reg_model="lm"` or `is_early_stopping=False`.
            early_stopping_patience (int, optional): The number of consequentive epochs with 
                barely-decreasing loss needed for training to be early stopped. This argument is 
                not used if `reg_model="lm"` or `is_early_stopping=False`.
            early_stopping_min_delta (int for float, optional): The minimum amount of decrease 
                in the loss so that the rounded is not considered barely-decreasing by the early 
                stopping mechanism. This argument is not used if `reg_model="lm"` or 
                `is_early_stopping=False`.
        """

        z_space = np.array(z_space)
        '''if action_space is not None:
            action_space = np.array(action_space)
        if (is_action_onehot) and (action_space is None):
            raise ValueError('One hot encoding of actions requires action_space to be not None.')'''

        self.reg_model = reg_model
        self.hidden_dims = hidden_dims
        self.epochs = epochs
        self.learning_rate = learning_rate
        self.batch_size = batch_size
        self.is_action_onehot = is_action_onehot
        self.is_normalized = is_normalized
        #self.action_space = action_space
        self.action_space = np.array([a for a in range(num_actions)]).reshape(-1, 1)
        self.num_actions = num_actions
        self.z_space = z_space
        self.zdim = z_space.shape[-1]
        self.__name__ = 'SequentialPreprocessor'

        # tunnable parameters
        self.is_early_stopping = is_early_stopping
        self.test_size = test_size
        self.early_stopping_patience = early_stopping_patience
        self.early_stopping_min_delta = early_stopping_min_delta
        self.cross_folds = cross_folds
        self.mode = mode

    def encode_a(self, a: np.ndarray) -> np.ndarray:
        enc = OneHotEncoder(categories=[self.action_space.flatten()], drop=None)
        return enc.fit_transform(a.reshape(-1, 1)).toarray()

    def _learn_initial_model(
            self, 
            xs: np.ndarray, 
            zs: np.ndarray
        ) -> dict[tuple[Union[int, float], ...], np.ndarray]:
        # learn model at time 0
        model0 = {}
        for z in np.unique(zs, axis=0):
            idx_z = np.all(zs == z, axis=1)
            model0[tuple(z)] = np.mean(xs[idx_z, 0, :], axis=0)
        return model0

    def _learn_transition_models(
            self, 
            xs: np.ndarray, 
            zs: np.ndarray, 
            actions: np.ndarray, 
            rewards: np.ndarray
        ) -> LinearRegression | NeuralNetRegressor:
        # learn model after time 0
        N, T, _ = xs.shape
        if self.is_normalized:
            states, self.states_mean, self.states_std = self.standardize(
                xs[:, : (T - 1), :].reshape(-1, self.xdim)
            )
            next_states, self.next_states_mean, self.next_states_std = self.standardize(
                np.concatenate(
                    [
                        xs[:, 1:T, :].reshape(-1, self.xdim),
                        rewards[:, :].reshape(-1, 1),
                    ],
                    axis=1,
                )
            )
        else:
            states = xs[:, : (T - 1), :].reshape(-1, self.xdim)
            next_states = np.concatenate(
                [xs[:, 1:T, :].reshape(-1, self.xdim), rewards[:, :].reshape(-1, 1)],
                axis=1,
            )

        if self.is_action_onehot:
            actions = self.encode_a(actions.reshape(-1, 1)).reshape(N, T - 1, -1)
            self.dim_a = actions.shape[-1]
        else:
            self.dim_a = 1

        if self.reg_model == "lm":
            return self._learn_linear_model(states, next_states, zs, actions, T)
        elif self.reg_model == 'nn':
            return self._learn_neural_model(states, next_states, zs, actions, T)
        else:
            print("Model type is undefined. Please specify either \"lm\" or \"nn\".")
            exit(1)

    def _learn_linear_model(
            self, 
            states: np.ndarray, 
            next_states: np.ndarray, 
            zs: np.ndarray, 
            actions: np.ndarray, 
            T: int
        ) -> LinearRegression:
        X = np.concatenate(
            [
                np.repeat(zs.reshape(-1, 1, self.zdim), repeats=T - 1, axis=1).reshape(
                    -1, self.zdim
                ),
                actions[:, : (T - 1), np.newaxis].reshape(-1, self.dim_a),
                states,
            ],
            axis=1,
        )
        Y = next_states
        return LinearRegression().fit(X, Y)

    def _learn_neural_model(
            self, 
            states: np.ndarray, 
            next_states: np.ndarray, 
            zs: np.ndarray, 
            actions: np.ndarray, 
            T: int
        ) -> NeuralNetRegressor:
        if self.mode == "single":
            return self._learn_single_neural_model(states, next_states, zs, actions, T)
        elif self.mode == "sensitive":
            return self._learn_sensitive_neural_model(
                states, next_states, zs, actions, T
            )
        else: 
            print("Model mode is undefined. Please specify either \"single\" or \"sensitive\".")
            exit(1)


    def _learn_single_neural_model(
            self, 
            states: np.ndarray, 
            next_states: np.ndarray, 
            zs: np.ndarray, 
            actions: np.ndarray, 
            T: int
        ) -> NeuralNetRegressor:
        X = np.concatenate(
            [
                np.repeat(zs.reshape(-1, 1, self.zdim), repeats=T - 1, axis=1).reshape(
                    -1, self.zdim
                ),
                actions[:, : (T - 1), np.newaxis].reshape(-1, self.dim_a),
                states,
            ],
            axis=1,
        )
        Y = next_states
        model = NeuralNetRegressor(
            in_dim=X.shape[1], out_dim=Y.shape[1], hidden_dims=self.hidden_dims
        )
        model.fit( # there used to be mistakenly calling "model.train()"
            X,
            Y,
            epochs=self.epochs,
            learning_rate=self.learning_rate,
            batch_size=self.batch_size,
            is_early_stopping=self.is_early_stopping,
            early_stopping_patience=self.early_stopping_patience,
            early_stopping_min_delta=self.early_stopping_min_delta,
            test_size=self.test_size,
        )
        return model

    def _learn_sensitive_neural_model(
            self, 
            states: np.ndarray, 
            next_states: np.ndarray, 
            zs: np.ndarray, 
            actions: np.ndarray, 
            T: int
        ) -> NeuralNetRegressor:
        model = {}
        zs = np.repeat(zs[:, np.newaxis, :], axis=1, repeats=T - 1).reshape(
            -1, self.zdim
        )
        for z in np.unique(zs, axis=0):
            idx_z = np.all(zs == z, axis=1)
            states_z = states[idx_z].reshape(-1, self.xdim)
            next_states_z = next_states[idx_z].reshape(-1, next_states.shape[-1])
            actions_z = actions[:, : (T - 1)].reshape(-1, self.dim_a)[idx_z]
            X = np.concatenate([actions_z, states_z], axis=1)
            Y = next_states_z

            model[tuple(z)] = NeuralNetRegressor(
                in_dim=X.shape[1], out_dim=Y.shape[1], hidden_dims=self.hidden_dims
            )
            model[tuple(z)].fit(
                X,
                Y,
                epochs=self.epochs,
                learning_rate=self.learning_rate,
                batch_size=self.batch_size,
                is_early_stopping=self.is_early_stopping,
                early_stopping_patience=self.early_stopping_patience,
                early_stopping_min_delta=self.early_stopping_min_delta,
                test_size=self.test_size,
            )
        return model

    def learn_transition_models(
            self, 
            xs: np.ndarray, 
            zs: np.ndarray, 
            actions: np.ndarray, 
            rewards: np.ndarray
        ) -> tuple[dict[tuple[Union[int, float], ...], np.ndarray], 
                        Union[LinearRegression, NeuralNetRegressor]]:
        model0 = self._learn_initial_model(xs, zs)
        model = self._learn_transition_models(xs, zs, actions, rewards)
        return model0, model

    def learn_marginal_dist_z(
            self, 
            zs: np.ndarray
        ) -> dict[tuple[Union[int, float], ...], Union[int, float]]:
        marginal_dist_z = {}
        self.z_space = np.unique(zs, axis=0)
        for z in np.unique(zs, axis=0):
            z_idx = np.all(zs == z, axis=1)
            marginal_dist_z[tuple(z)] = sum(z_idx) / len(z_idx)
        return marginal_dist_z

    def _estimate_cf_next_state_reward_mean_tg1(
            self, 
            model: LinearRegression | NeuralNetRegressor, 
            z: np.ndarray, 
            at: np.ndarray, 
            xt: np.ndarray
        ) -> np.ndarray:
        N = xt.shape[0]
        if self.is_normalized:
            state = self.standardize(xt, self.states_mean, self.states_std)
        else:
            state = xt

        if self.is_action_onehot:
            encoded = self.encode_a(at.reshape(-1, 1))
            at = encoded.reshape(N, -1)
            dim_a = at.shape[-1]
        else:
            dim_a = 1

        if self.mode == "single":
            m = model.predict(
                np.concatenate(
                    [
                        z,
                        at.reshape(-1, dim_a),
                        state,
                    ],
                    axis=1,
                )
            )
        elif self.mode == "sensitive":
            m = np.zeros((xt.shape[0], self.xdim + 1))
            for z_ in self.z_space:
                idx_z = np.all(z == z_, axis=1)
                states_z = state[idx_z]
                actions_z = at[idx_z].reshape(-1, dim_a)
                X = np.concatenate([actions_z, states_z], axis=1)
                m[idx_z] = model[tuple(z_)].predict(X)
        if self.is_normalized:
            m = self.destandardize(m, self.next_states_mean, self.next_states_std)
        return m

    def _process_initial_state(
            self, 
            initial_model: dict[tuple[Union[int, float], ...], np.ndarray], 
            z: np.ndarray, 
            xt: np.ndarray
        ) -> tuple[np.ndarray, dict[tuple[Union[int, float], ...], np.ndarray]]:
        zs = z
        del(z)
        N = xt.shape[0]
        epsilon_hat = xt - np.array([initial_model[tuple(z.flatten())] for z in zs])
        xt_c = {
            key: np.broadcast_to(initial_model[key], (N, self.xdim)) + epsilon_hat
            for key in self.marginal_dist_z
        }
        xt_tilde = np.hstack([xt_c[key] for key in self.marginal_dist_z])
        return xt_tilde, xt_c

    def _process_subsequent_states(
        self, 
        transition_model: LinearRegression | NeuralNetRegressor, 
        z: np.ndarray, 
        xt: np.ndarray, 
        xtm1: np.ndarray, 
        atm1: np.ndarray, 
        rtm1: np.ndarray | None = None
    ) -> tuple[np.ndarray, np.ndarray, dict[tuple[Union[int, float], ...], np.ndarray]]:
        N = xt.shape[0]
        m = self._estimate_cf_next_state_reward_mean_tg1(
            model=transition_model, z=z, at=atm1, xt=xtm1
        )
        xt_mean = m[:, :-1]
        epsilon_hat = xt - xt_mean

        if rtm1 is not None:
            rtm1_mean = m[:, -1]
            epsilon_hat_reward = rtm1 - rtm1_mean

        xt_c = {}
        rtm1_c = {}
        for key, prob in self.marginal_dist_z.items():
            key_vec = np.repeat(np.array(key).reshape(1, -1), repeats=N, axis=0)
            m = self._estimate_cf_next_state_reward_mean_tg1(
                model=transition_model, z=key_vec, at=atm1, xt=self.buffer[key]
            )
            xt_mean = m[:, :-1]
            xt_c[key] = xt_mean + epsilon_hat
            if rtm1 is not None:
                rtm1_mean = m[:, -1]
                rtm1_c[key] = rtm1_mean + epsilon_hat_reward

        xt_tilde = np.hstack(
            [xt_c[key] * 1 for key, prob in self.marginal_dist_z.items()]
        )
        if rtm1 is not None:
            rtm1_tilde = np.sum(
                [rtm1_c[key] * prob for key, prob in self.marginal_dist_z.items()],
                axis=0,
            )
        else:
            rtm1_tilde = None

        return xt_tilde, rtm1_tilde, xt_c

    def train_preprocessor(
            self, 
            zs: list | np.ndarray, 
            xs: list | np.ndarray, 
            actions: list | np.ndarray, 
            rewards: list | np.ndarray
        ) -> tuple[np.ndarray, np.ndarray]:
        r"""
        Train the sequential preprocessor and preprocess the training trajectory.

        When more than 1 cross folds are specified, then the training trajectory will be 
        preprocessed in `train_preprocessor` following the idea of double machine learning. 
        The detailed preprocessing procedure is outlined in the real data analysis workflow 
        in the "Example Workflows" section.

        Args: 
            zs (list or np.ndarray): A 2D list or array of shape (N, zdim) where N is the 
                number of individuals in the training set and zdim is the dimension 
                of the sensitive attribute variable. It contains the observed sensitive 
                attribute for each individual in the training set. The observed sensitive 
                attribute for each individual should occupy a separate row in the list or 
                array.
            xs (list or np.array): A 3D list or array of shape (N, T+1, xdim) where N is the 
                 number of individuals in the training set, T is the total number of 
                 environment transitions, and xdim is the dimension of the state variable. 
                 It contains the full state trajectory of each individual in the training set. 
                 Specifically, `xs[i, j]` should be the state vector of the i-th individual 
                 at the j-th time step (i.e. :math:`s_{ij}`).
            actions (list or np.array): A 2D list or array of shape (N, T) where N is the 
                number of individuals in the training set and T is the total number of 
                environment transitions. It contains the full action trajectory of each 
                individual in the training set. Specifically, `actions[i, j]` should be the 
                action of the i-th individual at the j-th time step (i.e. :math:`a_{ij}`).
            rewards (list or np.array): A 2D list or array of shape (N, T) where N is the 
                number of individuals in the training set and T is the total number of 
                environment transitions. It contains the full reward trajectory of each 
                individual in the training set. Specifically, `rewards[i, j]` should be the 
                reward of the i-th individual at the j-th time step (i.e. :math:`r_{ij}`).

        Returns:
            xs_tilde (np.ndarray): A 3D array of shape (N, T+1, xdim*K) where N is the 
                number of individuals in the training set, T is the total number of 
                environment transitions, xdim is the dimension of the state variable, and 
                K is the total number of legit values of the sensitive attribute. It 
                contains the preprocessed state trajectory of each individual in the 
                training set. Specifically, `xs_tilde[i, j]` should be the preprocessed 
                state vector of the i-th individual at the j-th time step (i.e. 
                :math:`\tilde{s}_{ij}`).
            rs_tilde (np.ndarray): A 2D array of shape (N, T) where N is the 
                number of individuals in the training set and T is the total number of 
                environment transitions. It contains the preprocessed reward trajectory of 
                each individual in the training set. Specifically, `rs_tilde[i, j]` should 
                be the preprocessed reward of the i-th individual at the j-th time step 
                (i.e. :math:`\tilde{r}_{ij}`).  
        """

        zs = np.array(zs)
        xs = np.array(xs)
        actions = np.array(actions)
        rewards = np.array(rewards)

        # some convenience variables
        N, T, xdim = xs.shape
        self.N, self.T, self.xdim = xs.shape

        # learn marginal distribution of z
        self.marginal_dist_z = self.learn_marginal_dist_z(zs)

        # learn transition models, estimate residuals and estimate counterfactual outcome
        self.model0 = [None for _ in range(self.cross_folds)]
        self.model = [None for _ in range(self.cross_folds)]

        if self.cross_folds == 1:
            self.model0[0], self.model[0] = self.learn_transition_models(
                xs=xs, zs=zs, actions=actions, rewards=rewards
            )
            self.reset_buffer(n=N)
            xs_tilde = np.zeros([N, T, xdim * len(self.marginal_dist_z.keys())])
            rs_tilde = np.zeros([N, T - 1])
            for t in range(T):
                if t == 0:
                    xt_tilde, xt_c = self._process_initial_state(
                        initial_model=self.model0[0], xt=xs[:, 0, :], z=zs
                    )
                else:
                    xt_tilde, rtm1_tilde, xt_c = self._process_subsequent_states(
                        transition_model=self.model[0],
                        xt=xs[:, t, :],
                        xtm1=xs[:, t - 1, :],
                        z=zs,
                        atm1=actions[:, t - 1],
                        rtm1=rewards[:, t - 1],
                    )
                    rs_tilde[:, t - 1] = rtm1_tilde
                self.buffer = xt_c.copy()
                xs_tilde[:, t, :] = xt_tilde
        else:
            kf = KFold(n_splits=self.cross_folds)
            xs_tilde = np.zeros([N, T, xdim * len(self.marginal_dist_z.keys())])
            rs_tilde = np.zeros([N, T - 1])
            for i, (train_index, test_index) in enumerate(kf.split(xs)):
                xs_train, xs_test = xs[train_index], xs[test_index]
                zs_train, zs_test = zs[train_index], zs[test_index]
                actions_train, actions_test = actions[train_index], actions[test_index]
                rewards_train, rewards_test = rewards[train_index], rewards[test_index]
                self.model0[i], self.model[i] = self.learn_transition_models(
                    xs=xs_train,
                    zs=zs_train,
                    actions=actions_train,
                    rewards=rewards_train,
                )
                n = xs_test.shape[0]
                self.reset_buffer(n=n)
                for t in range(T):
                    if t == 0:
                        xt_tilde_test, xt_c_test = self._process_initial_state(
                            initial_model=self.model0[i], xt=xs_test[:, 0, :], z=zs_test
                        )
                    else:
                        xt_tilde_test, rtm1_tilde_test, xt_c_test = (
                            self._process_subsequent_states(
                                transition_model=self.model[i],
                                xt=xs_test[:, t, :],
                                xtm1=xs_test[:, t - 1, :],
                                z=zs_test,
                                atm1=actions_test[:, t - 1],
                                rtm1=rewards_test[:, t - 1],
                            )
                        )
                        rs_tilde[test_index, t - 1] = rtm1_tilde_test
                    xs_tilde[test_index, t, :] = xt_tilde_test
                    self.buffer = xt_c_test.copy()
        return xs_tilde, rs_tilde

    # SEEMS WE CANNOT PREPROCESS A SINGLE STEP THAT'S NOT CONSECUTIVE? CUZ THEN THE INFO IN THE 
    # BUFFER WOULD BE INCORRECT? (BUFFER STORES THE COUNTERFACTUAL STATES FROM LAST FUNCTION CALL, 
    # IDEALLY IT IS THE COUNTERFACTUAL STATES FROM THE PREVIOUS STEP.)
    def preprocess_single_step(
            self, 
            z: list | np.ndarray, 
            xt: list | np.ndarray, 
            xtm1: list | np.ndarray | None = None, 
            atm1: list | np.ndarray | None = None, 
            rtm1: list | np.ndarray | None = None, 
            **kwargs
        ) -> tuple[np.ndarray, np.ndarray] | np.ndarray:
        r"""
        Preprocess one single time step of the trajectory.

        Important Note: A `SequentialPreprocessor` object internally tracks the preprocessed 
        counterfactual states from the previous time step using a states buffer. In this case, 
        suppose `preprocess_single_step()` is called on a set of transitions at time :math:`t` 
        in some trajectory. Then, at the next call of `preprocess_single_step()` for this 
        instance of `SequentialPreprocessor`, the transitions passed to the function must be 
        from time :math:`t+1` of the same trajectory. To preprocess another trajectory, either 
        use another instance of `SequentialPreprocessor`, or pass the initial step of the trajectory 
        to `preprocess_single_step()` with `xtm1=None` and `atm1=None`.

        In general, unless step-wise preprocessing is necessary, we recommend using 
        `preprocess_multiple_steps` to preprocess a whole trajectory to avoid unintended bugs.

        Args: 
            zs (list or np.ndarray): A 2D list or array of shape (N, zdim) where N is the 
                number of individuals in the trajectory to be processed and zdim is the dimension 
                of the sensitive attribute variable. It contains the observed sensitive 
                attribute for each individual in the trajectory to be processed. The observed sensitive 
                attribute for each individual should occupy a separate row in the list or 
                array.
            xt (list or np.array): A 2D list or array of shape (N, xdim) where N is the 
                 number of individuals in the trajectory to be processed and xdim is the dimension 
                 of the state variable. It contains the state vector of each individual 
                 in the trajectory at the time step that is to be processed. Specifically, `xt[i]` 
                 should be the state vector of the i-th individual.
            xtm1 (list or np.array or None): A 3D list or array of shape (N, xdim) where N is the 
                 number of individuals in the trajectory to be processed and xdim is the dimension 
                 of the state variable. It contains the state vector of each individual 
                 in the trajectory at the previous timestep (i.e. :math:`s_{t-1}`). Specifically, 
                 `xtm1[i]` should be the state vector of the i-th individual.
            atm1 (list or np.array or None): A 2D list or array of shape (N, 1) where N is the 
                number of individuals in the trajectory to be processed. It contains the action of each 
                individual in the trajectory at the previous time step (i.e. :math:`a_{t-1}`). 
                Specifically, `atm1[i]` should be the action of the i-th individual. When both `xtm1` 
                and `atm1` are set to `None`, the preprocessor will consider the input to be from the 
                initial time step of a new trajectory, and the buffer of previous counterfactual states 
                will be reset.
            rtm1 (list or np.array or None): A 2D list or array of shape (N, 1) where N is the 
                number of individuals in the trajectory to be processed. It contains the reward of each 
                individual in the trajectory at the previous time step (i.e. :math:`r_{t-1}`). 
                Specifically, `rtm1[i]` should be the action of the i-th individual.

        Returns:
            xt_tilde (np.ndarray): A 2D array of shape (N, xdim*K) where N is the 
                number of individuals in the trajectory to be processed, xdim is the dimension of the 
                state variable, and K is the total number of legit values of the sensitive 
                attribute. It contains the preprocessed state trajectory of each individual 
                in the trajectory. Specifically, `xt_tilde[i]` should be the preprocessed 
                state vector of the i-th individual.
            rt_tilde (np.ndarray, optional): A 2D array of shape (N, 1) where N is the 
                number of individuals in the trajectory to be processed. It contains the preprocessed 
                reward of each individual in the trajectory. Specifically, `rs_tilde[i]` should 
                be the preprocessed reward of the i-th individual. `rt_tilde` is not returned 
                if `rtm1=None` in the function input.  
        """

        z = np.array(z)
        xt = np.array(xt)
        if xtm1 is not None:
            xtm1 = np.array(xtm1)
        if atm1 is not None:
            atm1 = np.array(atm1)
        if rtm1 is not None:
            rtm1 = np.array(rtm1)

        # some convenience variables
        N, xdim = xt.shape
        cross_folds = len(self.model)

        # check if state dimension of the input is the same as state dimension of the training data
        if xdim != self.xdim:
            raise ValueError('The state dimension of the input does not match that of the training data.')

        # t = 0
        if xtm1 is None and atm1 is None:
            self.reset_buffer(n=N)
            if self.cross_folds == 1:
                xt_tilde, xt_c = self._process_initial_state(initial_model=self.model0[0], xt=xt, z=z)
                self.buffer = xt_c.copy()
            else:
                buffer_tmp = {key: np.zeros_like(xt) for key in self.marginal_dist_z}
                xt_tilde = np.zeros((N, self.xdim * len(self.marginal_dist_z.keys())))
                for k in range(cross_folds):
                    xt_tilde_k, xt_c_k = self._process_initial_state(
                        initial_model=self.model0[k], xt=xt, z=z
                    )
                    buffer_tmp = {
                        key: buffer_tmp[key] + xt_c_k[key] / cross_folds
                        for key in self.marginal_dist_z
                    }
                    xt_tilde += xt_tilde_k / cross_folds
                self.buffer = buffer_tmp.copy()
        else:
            if cross_folds == 1:
                xt_tilde, rtm1_tilde, xt_c = self._process_subsequent_states(
                    transition_model=self.model[0], xt=xt, xtm1=xtm1, z=z, atm1=atm1, rtm1=rtm1
                )
                self.buffer = xt_c.copy()
            else:
                buffer_tmp = {key: np.zeros_like(xt) for key in self.marginal_dist_z}
                xt_tilde = np.zeros((N, self.xdim * len(self.marginal_dist_z.keys())))
                if rtm1 is not None:
                    rtm1_tilde = np.zeros_like(rtm1)
                for k in range(cross_folds):
                    xt_tilde_k, rtm1_tilde_k, xt_c_k = self._process_subsequent_states(
                        transition_model=self.model[k], xt=xt, xtm1=xtm1, z=z, atm1=atm1, rtm1=rtm1
                    )
                    buffer_tmp = {
                        key: buffer_tmp[key] + xt_c_k[key] / cross_folds
                        for key in self.marginal_dist_z
                    }
                    xt_tilde += xt_tilde_k / cross_folds
                    if rtm1 is not None:
                        rtm1_tilde += rtm1_tilde_k / cross_folds
                self.buffer = buffer_tmp.copy()
        return (xt_tilde, rtm1_tilde) if rtm1 is not None else xt_tilde
    
    def preprocess_multiple_steps(
            self, 
            zs: list | np.ndarray, 
            xs: list | np.ndarray, 
            actions: list | np.ndarray, 
            rewards: list | np.ndarray | None = None
        ) -> tuple[np.ndarray, np.ndarray] | np.ndarray:
        r"""
        Preprocess a whole trajectory.

        Args: 
            zs (list or np.ndarray): A 2D list or array of shape (N, zdim) where N is the 
                number of individuals in the trajectory and zdim is the dimension 
                of the sensitive attribute variable. It contains the observed sensitive 
                attribute for each individual in the trajectory. The observed sensitive 
                attribute for each individual should occupy a separate row in the list or 
                array.
            xs (list or np.array): A 3D list or array of shape (N, T+1, xdim) where N is the 
                 number of individuals in the trajectory, T is the total number of 
                 environment transitions, and xdim is the dimension of the state variable. 
                 It contains the full state trajectory of each individual. 
                 Specifically, `xs[i, j]` should be the state vector of the i-th individual 
                 at the j-th time step (i.e. :math:`s_{ij}`).
            actions (list or np.array): A 2D list or array of shape (N, T) where N is the 
                number of individuals in the trajectory and T is the total number of 
                environment transitions. It contains the full action trajectory of each 
                individual. Specifically, `actions[i, j]` should be the 
                action of the i-th individual at the j-th time step (i.e. :math:`a_{ij}`).
            rewards (list or np.array or None): A 2D list or array of shape (N, T) where N is the 
                number of individuals in the trajectory and T is the total number of 
                environment transitions. It contains the full reward trajectory of each 
                individual. Specifically, `rewards[i, j]` should be the 
                reward of the i-th individual at the j-th time step (i.e. :math:`r_{ij}`).

        Returns:
            xs_tilde (np.ndarray): A 3D array of shape (N, T+1, xdim*K) where N is the 
                number of individuals in the trajectory, T is the total number of 
                environment transitions, xdim is the dimension of the state variable, and 
                K is the total number of legit values of the sensitive attribute. It 
                contains the preprocessed state trajectory of each individual. 
                Specifically, `xs_tilde[i, j]` should be the preprocessed 
                state vector of the i-th individual at the j-th time step (i.e. 
                :math:`\tilde{s}_{ij}`).
            rs_tilde (np.ndarray): A 2D array of shape (N, T) where N is the 
                number of individuals in the trajectory and T is the total number of 
                environment transitions. It contains the preprocessed reward trajectory of 
                each individual. Specifically, `rs_tilde[i, j]` should 
                be the preprocessed reward of the i-th individual at the j-th time step 
                (i.e. :math:`\tilde{r}_{ij}`). `rs_tilde` is not returned if `rtm1=None` in 
                the function input. 
        """

        zs = np.array(zs)
        xs = np.array(xs)
        actions = np.array(actions)
        if rewards is not None:
            rewards = np.array(rewards)

        # some convenience variables
        N, T, xdim = xs.shape

        # check if state dimension of the input is the same as state dimension of the training data
        if xdim != self.xdim:
            raise ValueError('The state dimension of the input does not match that of the training data.')
        
        # define the returned arrays; the arrays will be filled later
        xs_tilde = np.zeros([N, T, xdim * len(self.marginal_dist_z.keys())])
        rs_tilde = np.zeros([N, T - 1])

        # preprocess the initial step
        xs_tilde[:, 0, :] = self.preprocess_single_step(z=zs, xt=xs[:, 0, :])

        # preprocess subsequent steps
        if rewards is not None:
            for t in range (1, T):
                xs_tilde[:, t, :], rs_tilde[:, t-1] = self.preprocess_single_step(z=zs, 
                                                                                  xt=xs[:, t, :], 
                                                                                  xtm1=xs[:, t-1, :], 
                                                                                  atm1=actions[:, t-1], 
                                                                                  rtm1=rewards[:, t-1]
                                                                                  )
            return xs_tilde, rs_tilde                
        else:
            for t in range (1, T):
                xs_tilde[:, t, :] = self.preprocess_single_step(z=zs, 
                                                                xt=xs[:, t, :], 
                                                                xtm1=xs[:, t-1, :], 
                                                                atm1=actions[:, t-1]
                                                                )
            return xs_tilde